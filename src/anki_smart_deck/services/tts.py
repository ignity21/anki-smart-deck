import random
from typing import List, Tuple
from anki_smart_deck.config import get_config

from google.cloud import texttospeech_v1
from rich import print as rprint


class GoogleTTSService:
    def __init__(self):
        app_config = get_config()
        self._tts_cli = texttospeech_v1.TextToSpeechClient(
            client_options={"api_key": app_config.google_tts_key}
        )
        # ç¼“å­˜ WaveNet è¯­éŸ³åˆ—è¡¨ï¼Œé¿å…é‡å¤è°ƒç”¨ API
        self._wavenet_voices_cache = {}

    def list_all_voices(self, language_code="en-US"):
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ WaveNet è¯­éŸ³"""
        voices = self._tts_cli.list_voices(language_code=language_code)

        wavenet_voices = []
        for voice in voices.voices:
            if "Wavenet" in voice.name or "WaveNet" in voice.name:
                wavenet_voices.append(voice.name)

        if wavenet_voices:
            rprint(
                f"\n[cyan]WaveNet è¯­éŸ³[/cyan] [yellow]({len(wavenet_voices)} ä¸ª)[/yellow]:"
            )
            for name in sorted(wavenet_voices):
                rprint(f"  [green]âœ“[/green] {name}")

        return wavenet_voices

    def get_wavenet_voices(self, language_code="en-US") -> List:
        """
        è·å– WaveNet è¯­éŸ³åˆ—è¡¨ï¼ˆå¸¦ç¼“å­˜ï¼‰

        Args:
            language_code: è¯­è¨€ä»£ç ï¼Œå¦‚ "en-US", "zh-CN" ç­‰

        Returns:
            WaveNet è¯­éŸ³å¯¹è±¡åˆ—è¡¨
        """
        # å¦‚æœå·²ç¼“å­˜ï¼Œç›´æ¥è¿”å›
        if language_code in self._wavenet_voices_cache:
            rprint(f"[dim]ğŸ“¦ ä½¿ç”¨ç¼“å­˜çš„ {language_code} è¯­éŸ³åˆ—è¡¨[/dim]")
            return self._wavenet_voices_cache[language_code]

        # è·å–æ‰€æœ‰è¯­éŸ³
        voices = self._tts_cli.list_voices(language_code=language_code)

        # ç­›é€‰ WaveNet è¯­éŸ³
        wavenet_voices = []
        for voice in voices.voices:
            if "Wavenet" in voice.name or "WaveNet" in voice.name:
                wavenet_voices.append(voice)

        # ç¼“å­˜ç»“æœ
        self._wavenet_voices_cache[language_code] = wavenet_voices
        rprint(
            f"[dim]ğŸ’¾ å·²ç¼“å­˜ {len(wavenet_voices)} ä¸ª {language_code} WaveNet è¯­éŸ³[/dim]"
        )

        return wavenet_voices

    def synthesize_with_random_voice(
        self,
        text: str,
        language_code: str = "en-US",
        audio_encoding: texttospeech_v1.AudioEncoding = texttospeech_v1.AudioEncoding.MP3,
        speaking_rate: float = 1.0,
        pitch: float = 0.0,
    ) -> Tuple[bytes, str]:
        """
        ä½¿ç”¨éšæœº WaveNet è¯­éŸ³åˆæˆæ–‡æœ¬

        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            language_code: è¯­è¨€ä»£ç 
            audio_encoding: éŸ³é¢‘ç¼–ç æ ¼å¼ï¼ˆMP3, LINEAR16, OGG_OPUS ç­‰ï¼‰
            speaking_rate: è¯­é€Ÿ (0.25 åˆ° 4.0ï¼Œ1.0 ä¸ºæ­£å¸¸)
            pitch: éŸ³è°ƒ (-20.0 åˆ° 20.0ï¼Œ0.0 ä¸ºæ­£å¸¸)

        Returns:
            (éŸ³é¢‘å†…å®¹, ä½¿ç”¨çš„è¯­éŸ³åç§°)
        """
        # è·å–å¯ç”¨çš„ WaveNet è¯­éŸ³
        available_voices = self.get_wavenet_voices(language_code)

        if not available_voices:
            raise ValueError(f"æ²¡æœ‰æ‰¾åˆ° {language_code} çš„ WaveNet è¯­éŸ³")

        # éšæœºé€‰æ‹©ä¸€ä¸ªè¯­éŸ³
        selected_voice = random.choice(available_voices)

        gender_name = texttospeech_v1.SsmlVoiceGender(selected_voice.ssml_gender).name
        gender_emoji = (
            "ğŸ‘¨" if "MALE" in gender_name else "ğŸ‘©" if "FEMALE" in gender_name else "ğŸ­"
        )

        rprint(
            f"ğŸ¤ [bold cyan]éšæœºé€‰æ‹©:[/bold cyan] [yellow]{selected_voice.name}[/yellow] {gender_emoji} [dim]({gender_name})[/dim]"
        )

        # é…ç½®åˆæˆè¾“å…¥
        synthesis_input = texttospeech_v1.SynthesisInput(text=text)

        # ä½¿ç”¨é€‰ä¸­çš„è¯­éŸ³
        voice = texttospeech_v1.VoiceSelectionParams(
            language_code=language_code, name=selected_voice.name
        )

        # é…ç½®éŸ³é¢‘è¾“å‡º
        audio_config = texttospeech_v1.AudioConfig(
            audio_encoding=audio_encoding, speaking_rate=speaking_rate, pitch=pitch
        )

        # æ‰§è¡Œåˆæˆ
        response = self._tts_cli.synthesize_speech(
            input=synthesis_input, voice=voice, audio_config=audio_config
        )

        audio_size_kb = len(response.audio_content) / 1024
        rprint(f"âœ… [green]åˆæˆæˆåŠŸ[/green] [dim]({audio_size_kb:.1f} KB)[/dim]")

        return response.audio_content, selected_voice.name

    def synthesize_with_specific_voice(
        self,
        text: str,
        voice_name: str,
        language_code: str = "en-US",
        audio_encoding: texttospeech_v1.AudioEncoding = texttospeech_v1.AudioEncoding.MP3,
        speaking_rate: float = 1.0,
        pitch: float = 0.0,
    ) -> bytes:
        """
        ä½¿ç”¨æŒ‡å®šè¯­éŸ³åˆæˆæ–‡æœ¬

        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            voice_name: è¯­éŸ³åç§°ï¼Œå¦‚ "en-US-Wavenet-A"
            language_code: è¯­è¨€ä»£ç 
            audio_encoding: éŸ³é¢‘ç¼–ç æ ¼å¼
            speaking_rate: è¯­é€Ÿ
            pitch: éŸ³è°ƒ

        Returns:
            éŸ³é¢‘å†…å®¹
        """
        rprint(f"ğŸ¯ [bold cyan]ä½¿ç”¨æŒ‡å®šè¯­éŸ³:[/bold cyan] [yellow]{voice_name}[/yellow]")

        synthesis_input = texttospeech_v1.SynthesisInput(text=text)

        voice = texttospeech_v1.VoiceSelectionParams(
            language_code=language_code, name=voice_name
        )

        audio_config = texttospeech_v1.AudioConfig(
            audio_encoding=audio_encoding, speaking_rate=speaking_rate, pitch=pitch
        )

        response = self._tts_cli.synthesize_speech(
            input=synthesis_input, voice=voice, audio_config=audio_config
        )

        audio_size_kb = len(response.audio_content) / 1024
        rprint(f"âœ… [green]åˆæˆæˆåŠŸ[/green] [dim]({audio_size_kb:.1f} KB)[/dim]")

        return response.audio_content

    def clear_cache(self):
        """æ¸…é™¤è¯­éŸ³ç¼“å­˜"""
        self._wavenet_voices_cache.clear()
        rprint("[yellow]ğŸ—‘ï¸  å·²æ¸…é™¤è¯­éŸ³ç¼“å­˜[/yellow]")
